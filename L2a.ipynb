{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motywacja\n",
    "\n",
    "Sieci neuronowe działają, ponieważ efektywnie aproksymują pewne rozkłady prawdopodobieństwa. Celem tych ćwiczeń jest zrozumienie, co konkretnie jest aproksymowane (chwilowo nie interesuje nas, w jaki sposób).\n",
    "Wiedza ta jest potrzebna, aby dobrze zaplanować architekturę modelu i poprawnie wybrać funkcję kosztu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele generatywne\n",
    "\n",
    "Zadaniem modeli generatywnych jest generowanie danych podobnych (pochodzących z tego samego rozkładu) do tych, które były obserwowane podczas uczenia.\n",
    "\n",
    "Do tej pory omawialiśmy modele dyskryminatywne - one z kolei uczą się \"opisywać\" dane, np. przypisując im klasę, do jakiej należą.\n",
    "\n",
    "Przykładowy efekt działania modelu generatywnego - zdjęcia sypialni\n",
    "\n",
    "<img src=\"figures/L2/gan2.png\">\n",
    "\n",
    "Przykładowy efekt niedziałania modelu generatywnego - zdjęcia psów (chyba)\n",
    "\n",
    "<img src=\"figures/L2/gan.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model generatywny rzutu monetą.\n",
    "\n",
    "Spróbujmy wytrenować model generatywny pewnej (być może niesymetrycznej) monety.\n",
    "\n",
    "Obserwacje to wyniki kolejnych rzutów monetą. Na ich podstawie model estymuje rozkład prawdopodobieństwa, z jakiego one pochodzą, czyli po prostu prawdopodobieństwo wylosowania orła - oznaczmy je literą $\\theta$. Uczenie modelu to estymowanie tego parametru.\n",
    "\n",
    "Następnie model może **generować** wyniki kolejnych rzutów. W tym wypadku jest to bardzo proste, wystarczy np. użyć generatora liczb losowych, który z prawdopodobieństwem $\\theta$ wypisze ORZEŁ, a z prawdopodobieństwem $1-\\theta$ będzie to RESZKA.\n",
    "\n",
    "Jeśli na przykład prawdziwe $\\theta$ wynosi $70\\%$, a wyestymowane $60\\%$, to zauważymy, że generowane dane nie są podobne do danych prawdziwych - ORZEŁ będzie pojawiał się zbyt rzadko. Jest to analogia do powyższych zdjęć psów. Poprawnie wytrenowany model będzie średnio generował tyle samo ORŁÓW, co prawdziwa moneta i w tym sensie dane pochodzące z modelu będą dla nas nieodróżnialne od danych prawdziwych (analogia do zdjęć sypialnii)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W powyższym przykładzie estymowany rozkład jest dyskretny (dwie możliwości: ORZEŁ i RESZKA), natomiast parametr $\\theta$ teoretycznie może przyjmować dowolną wartość z przedziału $[0,1]$ (a więc jest ciągły).\n",
    "\n",
    "Z uwagi na architekturę komputerów w praktyce wszystkie rozkłady i parametry zawsze będą dyskretne, liczba możliwych wartości $\\theta$ będzie zależeć przede wszystkim od precyzji użytych floatów.\n",
    "\n",
    "Rozpatrywanie wszystkich możliwych wartości parametrów jest oczywiście zbyt czasochłonne. Stosuje się więc przybliżenia, a w tym celu łatwiej myśleć o parametrach jako wielkościach ciągłych i korzystać z twierdzeń analizy matematycznej. Podobna uwaga dotyczy rozkładów prawdopodobieństwa - dla przykładu, jeśli chcemy wylosować obrazek, to myślimy o pikselach jako punktach pochodzących z ciągłej trójwymiarowej kostki (kolor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejście maximum likelihood\n",
    "\n",
    "Załóżmy, że w $10$ rzutach monetą otrzymaliśmy $7$ orłów i $3$ reszki (rzuty są od siebie niezależne, więc istotna jest tylko sumaryczna liczba orłów i reszek, a nie kolejność wyników).\n",
    "\n",
    "<span style=\"color:red\">\n",
    "Uwaga! W dalszej części notebooka zakładamy, że zaobserwowane wyniki rzutów monetą to: ORZEŁ, ORZEŁ, RESZKA, RESZKA, ORZEŁ, RESZKA, ORZEŁ, ORZEŁ, ORZEŁ, ORZEŁ. Skrótowo (i nie do końca poprawnie) będziemy dalej mówić o tym konkretnym ciągu wyników \"siedem orłów i trzy reszki\". Kolejność wyników faktycznie nie ma znaczenia, ale czym innym jest dziesięć wyników o znanej kolejności - nawet jeśli potem ona nie ma znaczenia - a czym innym informacja, że w dziesięciu rzutach wypadło 7 orłów i 3 reszki w nieznanej kolejności. W tym drugim przypadku należałoby we wzorach na likelihood uwzględnić również stałą 120 - na tyle różnych sposobów można ustawić w ciąg 7 orłów i 3 reszki.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:red\">\n",
    "Proszę również w tym kontekście zwrócić uwagę na Ćwiczenie 10.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:red\">\n",
    "Błąd znalazła Yasia Romanets, bardzo dziękujemy za pomoc :)\n",
    "</span>\n",
    "\n",
    "Zdefiniujmy funkcję likelihood:\n",
    "$$L(\\theta|\\mathrm{obserwacje}) := P(\\mathrm{obserwacje}|\\theta)$$\n",
    "\n",
    "Chcemy tak dobrać $\\theta$, aby zmaksymalizować $L$ - innymi słowy wybieramy taką wartość $\\theta$, przy której mielibyśmy największe szanse na uzyskanie wyników, które zaobserwowaliśmy.\n",
    "\n",
    "$$L(\\theta|\\mathrm{obserwacje}) = P(\\mathrm{siedem~orłów~i~trzy~reszki}|\\theta) = \\theta^7 (1-\\theta)^3$$\n",
    "\n",
    "Okazuje się, że w wypadku prób Bernoulliego (rzutów niesymetryczną monetą) $L$ jest maksymalizowane przez:\n",
    "$$\\theta = \\frac{\\mathrm{liczba~sukcesów}}{\\mathrm{liczba~prób}}$$\n",
    "Innymi słowy, jeśli w $10$ rzutach wypadło $7$ orłów, to szacujemy prawdopodobieństwo wyrzucenia orła na $\\frac{7}{10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 1 (0,5 pkt)\n",
    "\n",
    "Narysować wykres funkcji $L(\\theta)$ dla $\\theta\\in[0,1]$. Zobaczyć, że maksimum jest w punkcie $\\frac{7}{10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11961ea10>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1161f2790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def L(theta):\n",
    "    return math.pow(theta,7) * math.pow((1-theta),3)\n",
    "\n",
    "theta_grid = np.linspace(0,1)\n",
    "L_values = []\n",
    "for theta in theta_grid:\n",
    "    L_values.append(L(theta))\n",
    "plt.plot(theta_grid, L_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2 (0,5 pkt)\n",
    "\n",
    "Symulator \"prawdziwej\" monety.\n",
    "\n",
    "Napisać funkcję flip_coin, która generuje wynik nb_flips rzutów monetą z prawdopodobieństwem wypadnięcia orła równym theta. Funkcja ma zwrócić tablicę zer i jedynek ($0$ - RESZKA, $1$ - ORZEŁ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flip_coin(theta, nb_flips):\n",
    "    result = np.random.binomial(1, theta, nb_flips)\n",
    "    assert len(result) == nb_flips\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3 (1 pkt)\n",
    "\n",
    "Pierwszy model generatywny rzutu monetą.\n",
    "\n",
    "Napisać klasę CoinML (Maximum Likelihood) posiadającą metody fit i toss:\n",
    "- fit - przyjmuje listę obserwacji i oblicza self.theta korzystając z wzoru powyżej.\n",
    "- toss - generuje jeden rzut monetą z prawdopodobieństwem self.theta i zwraca 0 lub 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CoinML(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.theta = X.count(1)/float(len(X))\n",
    "\n",
    "    def toss(self):\n",
    "        return flip_coin(self.theta, 1)\n",
    "    \n",
    "coin = CoinML()\n",
    "coin.fit([0,1])\n",
    "coin.toss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzór Bayesa\n",
    "\n",
    "Załóżmy teraz, że w \"fabryce monet\" produkowane są tylko monety symetryczne ($\\theta = 0.5$) oraz monety z wadą ($\\theta = 0.6$).\n",
    "\n",
    "W 10 rzutach monetą otrzymaliśmy 7 orłów i 3 reszki. Jak teraz wybrać właściwe $\\theta$?\n",
    "\n",
    "Można np. porównać $L(0.5) < L(0.6)$ i zdecydować się na $\\theta=0.6$.\n",
    "\n",
    "Załóżmy inaczej - wiemy, że średnio co piąta moneta produkowana jest z wadą. Czy wtedy też wybierzemy $\\theta=0.6$? A jeśli tylko jedna na tysiąc jest wadliwa? Jak bardzo nieprawdopodobne musi być to, że nasza moneta jest wadliwa, abyśmy przestali wierzyć funkcji likelihood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xkcd.com/1132/\n",
    "\n",
    "https://www.explainxkcd.com/wiki/index.php/1132:_Frequentists_vs._Bayesians\n",
    "\n",
    "<img src=\"figures/L2/frequentists_vs_bayesians.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prawdopodobieństwo warunkowe - przypomnienie\n",
    "\n",
    "https://www.youtube.com/watch?v=H02B3aMNKzE\n",
    "\n",
    "<img src=\"figures/L2/cond_prob.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzór Bayesa\n",
    "\n",
    "A - parametry rozkładu.\n",
    "B - obserwacja.\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A)\\,P(A)}{P(B)}$$\n",
    "\n",
    "Wersja rozszerzona, używana np. wtedy (w praktyce zawsze), gdy nie znamy prawdopodobieństwa B, ale znamy je z osobna dla każdego zestawu parametrów A.\n",
    "\n",
    "$$P(B) = {\\sum_j P(B\\mid A_j) P(A_j)}$$\n",
    "$$P(A_i\\mid B) = \\frac{P(B\\mid A_i)\\,P(A_i)}{\\sum\\limits_j P(B\\mid A_j)\\,P(A_j)}$$\n",
    "\n",
    "Prawdopodobieństwa $P(A_i)$ po prawej stronie wzoru nazywamy wiedzą a priori, $P(A_i\\mid B)$ po lewej wiedzą a posteriori. Gdy pojawią się nowe obserwacje, wiedza a posteriori staje się znowu wiedzą a priori i stosujemy wzór Bayesa kolejny raz ($P(A_i\\mid B_{\\mathrm{stare}})$ podstawiamy pod $P(A_i)$ i liczymy $P(A_i\\mid B_{\\mathrm{nowe}})$). Niezależnie od obserwacji $P(B\\mid A_i)$ nie ulega zmianie (dlaczego?).\n",
    "\n",
    "Wróćmy do przykładu, w którym średnio co piąta moneta jest wadliwa. Niech $A_1$ oznacza $\\theta = 0.5$, a $A_2$ oznacza $\\theta = 0.6$. B to nasze obserwacje - siedem orłów i trzy reszki. Wtedy:\n",
    "- $P(A_1) = \\frac45$,\n",
    "- $P(A_2) = \\frac15$,\n",
    "- $P(B\\mid A_1) = (\\frac12)^7(\\frac12)^3 = \\frac{1}{1024}$,\n",
    "- $P(B\\mid A_2) = (\\frac{6}{10})^7(\\frac{4}{10})^3 = \\frac{17496}{9765625}$,\n",
    "- $P(A_1\\mid B) = \\frac{ \\frac45 \\frac{1}{1024} }{ \\frac45 \\frac{1}{1024} + \\frac15 \\frac{17496}{9765625} } \\approx 0.686$\n",
    "- $P(A_2\\mid B) = \\frac{ \\frac15 \\frac{17496}{9765625} }{ \\frac45 \\frac{1}{1024} + \\frac15 \\frac{17496}{9765625} } \\approx 0.314$\n",
    "\n",
    "Czyli wciąż jest około dwa razy większa szansa, że rzucamy symetryczną monetą!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uwaga 1.\n",
    "Obserwacje można podać w dowolnej kolejności, można podawać je po jednej i stosować wzór wielokrotnie, można po kilka, można wszystkie jednocześnie, a wynik będzie ten sam...\n",
    "\n",
    "#### Uwaga 2.\n",
    "...teoretycznie, bo w praktyce jeśli obserwacji jest dużo, to mamy szansę uzyskać błędny wynik ze względu na numeryczną niestabilność."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Najważniejsza rzecz do zrozumienia - robimy rozkład prawdopodobieństwa na rozkładach prawdopodobieństwa!\n",
    "\n",
    "<img src=\"figures/L2/dawg_bayes.jpg\">\n",
    "\n",
    "Nasza moneta jest opisana rozkładem prawdopodobieństwa na dwóch możliwych zdarzeniach elementarnych (wynikach rzutu) {ORZEŁ, RESZKA}:\n",
    "- $P(\\mathrm{ORZEŁ}) = \\theta$,\n",
    "- $P(\\mathrm{RESZKA}) = 1 - \\theta$.\n",
    "\n",
    "Na tych rozkładach robimy drugi rozkład prawdopodobieństwa:\n",
    "- $\\mathcal{P}(\\theta=0.5) = \\frac45$,\n",
    "- $\\mathcal{P}(\\theta=0.6) = \\frac15$.\n",
    "\n",
    "Rozkłady $P$ **nie ulegają zmianie**. Jest to rodzina wszystkich możliwych rozkładów, które bierzemy pod uwagę (w tym wypadku mamy dwa rozkłady dla dwóch różnych $\\theta$; zawsze zakładamy, że dokładnie jeden z nich jest \"prawdziwy\").\n",
    "\n",
    "Rozkład $\\mathcal{P}$ **ulega zmianie** po każdej nowej obserwacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwa sposoby interpretowania prawdopodobieństwa\n",
    "\n",
    "1. Jako cecha pewnego obiektu ($P$ jest \"wbudowaną\" własnością monety).\n",
    "\n",
    "2. Jako stan naszej wiedzy o świecie ($\\mathcal{P}$ nie jest cechą żadnej istniejącej rzeczy, dlatego może ulegać zmianom).\n",
    "\n",
    "Jeśli interpretujemy $\\mathcal{P}$ jako wiedzę, to nie powinna nas dziwić Uwaga 1.\n",
    "\n",
    "Przy dużej liczbie obserwacji cała gęstość rozkładu $\\mathcal{P}$ zaczyna koncentrować się bardzo blisko wokół prawdziwego $P$.\n",
    "\n",
    "Zazwyczaj jeśli rozkład $P$ zależy od parametrów - w tym wypadku $\\theta$ - to te parametry piszemy w indeksie dolnym. Jeśli rozpatrujemy wszystkie możliwe $\\theta$, to napisalibyśmy, że $\\{P_\\theta\\}_{\\theta\\in[0,1]}$ jest sparametryzowaną rodziną rozkładów prawdopodobieństwa.\n",
    "\n",
    "W bardziej skomplikowanych problemach nie da się sensownie sparametryzować kilkoma liczbami wszystkich możliwych rozkładów prawdopodobieństwa, ale mimo to czasem staramy się to zrobić. Dzięki temu można próbować udowadniać twierdzenia, które zakładają uproszczony obraz świata, a następnie stosować je jako heurystyki.\n",
    "\n",
    "Z punktu widzenia wzoru Bayesa rodzina rozpatrywanych rozkładów prawdopodobieństwa nie musi być wcale sparametryzowana - jeśli mamy zbiór takich rozkładów, to możemy je po prostu ponumerować i piszemy wtedy np. $\\mathcal{P}(P_1) = 0.7, \\mathcal{P}(P_2) = 0.1, \\mathcal{P}(P_3) = 0.15, \\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uwaga 3.\n",
    "\n",
    "Jeśli przyjmiemy, że pewien rozkład $P$ ma a priori $\\mathcal{P}$ równe zero, to $\\mathcal{P}$ a posteriori też będzie równe zero, niezależnie od siły dowodów przemawiających za tym konkretnym $P$. Dlatego nie należy wykluczać a priori żadnego $P$, jeśli nie jesteśmy całkowicie pewni, że jest ono niemożliwe.\n",
    "\n",
    "Przy braku wiedzy a priori trzeba tak dobrać $\\mathcal{P}$, aby wszędzie było niezerowe (np. jeśli bierzemy pod uwagę $n$ różnych rozkładów $P$, to $\\mathcal{P}$ jest równe stale $\\frac1n$; jeśli rozkłady są sparametryzowane odcinkiem $[a,b]$, to $\\mathcal{P}$ jest rozkładem jednostajnym na tym odcinku; jeśli rozkłady są sparametryzowane całą prostą rzeczywistą, to $\\mathcal{P}$ oczywiście nie może być rozkładem jednostajnym, wtedy używamy np. rozkładu Gaussa o średniej zero i wariancji jeden; itd.).\n",
    "\n",
    "#### Uwaga 4.\n",
    "\n",
    "W wypadku rzutu monetą mamy tylko dwa możliwe zdarzenia elementarne, więc wszystkie rozkłady można sparametryzować odcinkiem $[0,1]$.\n",
    "\n",
    "Dla kostki sześciennej jest podobnie - jest sześć zdarzeń elementarnych, więc wszystkie rozkłady można sparametryzować szóstkami nieujemnych liczb rzeczywistych, które sumują się do jedności (5-wymiarowy sympleks w $\\mathbb{R}^6$).\n",
    "\n",
    "W obu powyższych przypadkach zdarzeń elementarnych jest skończenie wiele, a możliwych rozkładów continuum.\n",
    "\n",
    "Ale co się dzieje, gdy zdarzeń elementarnych jest nieskończenie wiele? Można np. powiedzieć, że przestrzeń kolorów jest ciągła i wtedy wszystkich możliwych obrazków jest nieskończenie wiele (continuum). Da się udowodnić, że możliwych rozkładów prawdopodobieństwa $P$ wciąż jest continuum, ale ciężko nadać im jakąkolwiek strukturę i zdefiniować $\\mathcal{P}$ jako rozkład jednostajny na niej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejście maximum a posteriori\n",
    "\n",
    "Zasada postępowania jest prosta:\n",
    "1. Mamy dany pewien rozkład a priori oraz obserwacje.\n",
    "2. Korzystając ze wzoru Bayesa obliczamy rozkład a posteriori.\n",
    "3. Wybieramy ten rozkład $P$, którego prawdopodobieństwo a posteriori jest największe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 4 (1 pkt)\n",
    "\n",
    "Napisać klasę CoinMAP (Maximum A Posteriori) posiadającą metody fit i toss:\n",
    "- konstruktor - przyjmuje prior, który może np. być słownikiem (klucz - $\\theta$, wartość - jej prawdopodobieństwo a priori),\n",
    "- fit - przyjmuje listę obserwacji i uaktualnia self.knowledge, korzystając ze wzoru Bayesa, a następnie ustawia self.theta wybierając odpowiednią wartość z self.knowledge,\n",
    "- toss - generuje jeden rzut monetą z prawdopodobieństwem self.theta i zwraca 0 lub 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CoinMAP(object):\n",
    "\n",
    "    def __init__(self, prior):\n",
    "        self.knowledge = prior\n",
    "        self.theta = ...\n",
    "        \n",
    "    def fit(self, X):\n",
    "        ...\n",
    "\n",
    "    def toss(self):\n",
    "        ...\n",
    "\n",
    "model = CoinMAP({0.5: 0.8, 0.6: 0.2})\n",
    "model.fit(np.array([1,0,1,1,1,0,0,1,1,1]))\n",
    "print \"model.knowledge powinno wyjść {0.5: 0.686, 0.6: 0.314}\"\n",
    "print model.knowledge\n",
    "print \"Powinno wyjść 0.5:\", model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())\n",
    "\n",
    "model = CoinMAP({0.5: 0.5, 0.6: 0.2, 0.8: 0.3})\n",
    "model.fit(np.array([1,0,1,1,1,0,0,1,1,1]))\n",
    "print \"model.knowledge powinno wyjść {0.5: 0.362, 0.6: 0.265, 0.8: 0.373}\"\n",
    "print model.knowledge\n",
    "print \"Powinno wyjść 0.8:\", model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jedyne Słuszne Podejście - całka po rozkładzie a posteriori\n",
    "\n",
    "Dotychczas korzystaliśmy tylko z części wiedzy na temat rozkładów - dlaczego nie użyć jej całej?\n",
    "\n",
    "Jeśli wiemy, że z prawdopodobieństwem 0.686 prawdopodobieństwo wypadnięcia orła wynosi 0.5, a z prawdopodobieństwem 0.314 prawdopodobieństwo wypadnięcia orła wynosi 0.6, to jakie jest ostateczne prawdopodobieństwo wypadnięcia orła?\n",
    "\n",
    "$$P(\\mathrm{ORZEŁ}) = \\mathcal{P}(\\theta = 0.5)P(\\mathrm{ORZEŁ} \\mid \\theta = 0.5) + \\mathcal{P}(\\theta = 0.6)P(\\mathrm{ORZEŁ} \\mid \\theta = 0.6) = 0.686 * 0.5 + 0.314 * 0.6 \\approx 0.531 $$\n",
    "\n",
    "W wersji z większą liczbą możliwych wartości $\\theta$:\n",
    "$$P(\\mathrm{ORZEŁ}) = \\sum_{\\theta_j} \\mathcal{P}(\\theta = \\theta_j)P(\\mathrm{ORZEŁ} \\mid \\theta = \\theta_j) = \\sum_{\\theta_j} \\mathcal{P}(\\theta = \\theta_j)\\theta_j $$\n",
    "\n",
    "#### Uwaga 5.\n",
    "\n",
    "Opisane tu podejście jest jedynym poprawnym sposobem uczenia się rozkładu danych na podstawie obserwacji. Nie będzie niespodzianką fakt, że w praktyce jest ono niewykonalne..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 5 (2 pkt)\n",
    "\n",
    "Napisać klasę CoinBest, która działa jak CoinMAP z tą różnicą, że self.theta jest obliczane powyższym wzorem, a nie wybierane spośród wartości self.knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CoinBest(object):\n",
    "\n",
    "    def __init__(self, prior):\n",
    "        self.knowledge = prior\n",
    "        self.theta = ...\n",
    "        \n",
    "    def fit(self, X):\n",
    "        ...\n",
    "\n",
    "    def toss(self):\n",
    "        ...\n",
    "\n",
    "model = CoinBest({0.5: 0.8, 0.6: 0.2})\n",
    "model.fit(np.array([1,0,1,1,1,0,0,1,1,1]))\n",
    "print \"model.knowledge powinno wyjść {0.5: 0.686, 0.6: 0.314}\"\n",
    "print model.knowledge\n",
    "print \"Powinno wyjść około 0.53:\", model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())\n",
    "\n",
    "model = CoinBest({0.5: 0.5, 0.6: 0.2, 0.8: 0.3})\n",
    "model.fit(np.array([1,0,1,1,1,0,0,1,1,1]))\n",
    "print \"model.knowledge powinno wyjść {0.5: 0.362, 0.6: 0.265, 0.8: 0.373}\"\n",
    "print model.knowledge\n",
    "print \"Powinno wyjść około 0.64:\", model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównanie powyższych metod\n",
    "\n",
    "Wybiegnijmy trochę do przodu:\n",
    "- ML jest najgorsze, ale najprostsze,\n",
    "- ML z sensowną regularyzacją ma przybliżać MAP,\n",
    "- MAP przy dużej liczbie obserwacji przybliża całkę po rozkładzie a posteriori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda Monte Carlo\n",
    "(tak naprawdę metody, bo jest ich wiele, ale wszystkie opierają się na jednym prostym pomyśle)\n",
    "\n",
    "Przykład:\n",
    "\n",
    "Załóżmy, że opracowaliśmy nową strategię gry w Blackjacka, która zakłada m.in. zliczanie schodzących kart. Zanim zaczniemy stosować ją w kasynie chcemy upewnić się, że faktycznie jest ona skuteczna, to znaczy średnia wygrana jest większa od zera (albo średnia wygrana na godzinę gry jest większa od płacy minimalnej).\n",
    "\n",
    "Krupier gra deterministycznie, więc przebieg gry zależy tylko i wyłącznie od kolejności kart w talii. Niestety, takich ułożeń jest bardzo dużo, a ponadto zasady Blackjacka przewidują kilka specjalnych sytuacji, przez co bardzo ciężko (jeśli jest to w ogóle możliwe) zapisać wzór na średnią wygraną. Co zrobić w takiej sytuacji?\n",
    "\n",
    "Rozwiązanie:\n",
    "\n",
    "Skoro krupier jest deterministyczny, to rozgrywamy bardzo dużo (im więcej, tym lepiej) gier z symulowanym krupierem i uśredniamy wygrane.\n",
    "\n",
    "Monte Carlo!\n",
    "\n",
    "#### Uwaga 6.\n",
    "\n",
    "Jeśli tylko da się nie używać Monte Carlo, to należy nie używać Monte Carlo. Ale zazwyczaj się nie da."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paradoks Monty'ego Halla\n",
    "\n",
    "Przeliczmy jeszcze raz przykład z wykładu, korzystając ze wzoru Bayesa.\n",
    "\n",
    "Przypomnienie:\n",
    "\n",
    "Mamy trzy bramki, za jedną z nich znajduje się nagroda, za pozostałymi dwiema koza. Gracz wybiera jedną z trzech bramek. Prowadzący grę, który zna położenie nagrody, odsłania jedną z pozostałych dwóch bramek, przy czym zawsze w odsłoniętej bramce znajduje się koza. Gracz ma teraz możliwość zmiany bramki.\n",
    "\n",
    "Wersja z piorunem: po wybraniu bramki piorun trafia losowo w jedną z pozostałych dwóch i odsłania jej zawartość. Gracz ma możliwość zmiany bramki na drugą zasłoniętą.\n",
    "\n",
    "Zastanówmy się chwilę, jak zdefiniować $P$ i $\\mathcal{P}$. Interesującą nas wielkością jest prawdopodobieństwo wygranej po wybraniu pewnej ustalonej bramki. Załóżmy na chwilę, że nagroda znajduje się w pierwszej bramce. Wtedy prawdopodobieństwo wygranej przy wybraniu pierwszej bramki wynosi 100%, natomiast w wypadku drugiej i trzeciej jest to oczywiście 0%. Mówienie w tym miejscu o prawdopodobieństwach może wydawać się sztuczne, ale jest to konieczne, aby móc zastosować wzór Bayesa. Możemy myśleć o trzech bramkach jako o trzech monetach, z których dokładnie jedna ma $\\theta = 1$, a pozostałe dwie $0$.\n",
    "\n",
    "Jeśli trzy bramki zwracają nagrody z prawdopodobieństwami odpowiednio $\\theta_1$, $\\theta_2$ i $\\theta_3$, to zapiszemy taką sytuację jako:\n",
    "$$P \\sim (\\theta_1, \\theta_2, \\theta_3)$$\n",
    "\n",
    "W takim razie mamy dokładnie trzy możliwości:\n",
    "- $P_1 \\sim (1,0,0)$,\n",
    "- $P_2 \\sim (0,1,0)$,\n",
    "- $P_3 \\sim (0,0,1)$.\n",
    "\n",
    "Każda z nich jest a priori jednakowo prawdopodobna, możemy więc zapisać:\n",
    "- $\\mathcal{P}(P_1) = \\frac13$,\n",
    "- $\\mathcal{P}(P_2) = \\frac13$,\n",
    "- $\\mathcal{P}(P_3) = \\frac13$.\n",
    "\n",
    "Załóżmy teraz, że gracz wybrał na początku bramkę nr 1. Prowadzący odsłonił bramkę nr 2 i była tam koza. Jak zmieniła się wartość $\\mathcal{P}$? Zauważmy, że:\n",
    "- $P(\\mathrm{obserwacja}\\mid P_1) = \\frac12$ - ponieważ jeśli nagroda jest w pierwszej bramce, to prowadzący losowo odsłania bramkę nr 2 lub nr 3,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_2) = 0$ - nagroda nie może być w bramce z kozą,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_3) = 1$ - prowadzący musi odsłonić bramkę nr 2.\n",
    "\n",
    "Podstawiając do wzoru Bayesa (proszę przeliczyć to przynajmniej raz na kartce) otrzymamy ostatecznie:\n",
    "- $\\mathcal{P}(P_1\\mid\\mathrm{obserwacja}) = \\frac13$,\n",
    "- $\\mathcal{P}(P_2\\mid\\mathrm{obserwacja}) = 0$,\n",
    "- $\\mathcal{P}(P_3\\mid\\mathrm{obserwacja}) = \\frac23$\n",
    "\n",
    "na końcu dla każdej bramki liczymy prawdopodobieństwo wylosowania nagrody po wyborze tejże bramki - oczywiście w tym celu liczymy całkę po rozkładzie a posteriori i otrzymujemy prawdopodobieństwa: $\\frac13 * 1 + 0 * 0 + \\frac23 * 0 = \\frac13, \\frac13 * 0 + 0 * 1 + \\frac23 * 0 = 0, \\frac13 * 0 + 0 * 0 + \\frac23 * 1 = \\frac23$. Dlatego opłaca się zmienić bramkę na trzecią.\n",
    "\n",
    "Wersja z piorunem: gracz wybrał na początku bramkę nr 1. Piorun uderzył w bramkę nr 2 i była tam koza. Jak zmieniła się wartość $\\mathcal{P}$? Zauważmy, że:\n",
    "- $P(\\mathrm{obserwacja}\\mid P_1) = \\frac12$ - piorun uderza losowo,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_2) = 0$ - nagroda nie może być w bramce z kozą,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_3) = \\frac12$ - piorun uderza losowo.\n",
    "\n",
    "Podstawiając do wzoru Bayesa (proszę przeliczyć to przynajmniej drugi raz na kartce) otrzymamy ostatecznie:\n",
    "- $\\mathcal{P}(P_1\\mid\\mathrm{obserwacja}) = \\frac12$,\n",
    "- $\\mathcal{P}(P_2\\mid\\mathrm{obserwacja}) = 0$,\n",
    "- $\\mathcal{P}(P_3\\mid\\mathrm{obserwacja}) = \\frac12$\n",
    "\n",
    "a po policzeniu całek po rozkładzie a posteriori otrzymamy prawdopodobieństwa $\\frac12, 0, \\frac12$ i dlatego nie ma znaczenia, czy zmienimy bramkę na trzecią.\n",
    "\n",
    "Pytanie kontrolne - dlaczego musimy liczyć całki po rozkładzie a posteriori, skoro wynik wychodzi taki sam, jak rozkład a posteriori?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 6 (1 pkt)\n",
    "\n",
    "Zasymulować metodą Monte Carlo przebieg rozgrywki dla gracza, który:\n",
    "- nie zmienia bramki,\n",
    "- zawsze zmienia bramkę,\n",
    "\n",
    "w przypadku:\n",
    "- zwykłym,\n",
    "- z piorunem, a jeśli trafi w nagrodę to:\n",
    "\t- powtórka,\n",
    "\t- przegrana.\n",
    "\n",
    "Wypisać średnią wygraną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# spodziewany wynik:\n",
    "#  - bez zmiany bramki:\n",
    "#     - zwykły: 1/3\n",
    "#     - piorun z powtórką: 1/2\n",
    "#     - piorun z przegraną: 1/3\n",
    "#  - ze zmianą bramki:\n",
    "#     - zwykły: 2/3\n",
    "#     - piorun z powtórką: 1/2\n",
    "#     - piorun z przegraną: 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 7 (1 pkt)\n",
    "\n",
    "Losujemy $k=100$ razy liczbę od $1$ do $m=200$ z rozkładem jednostajnym. Ile średnio różnych liczb wylosujemy?\n",
    "Rozwiązać metodą Monte Carlo.\n",
    "\n",
    "https://math.dartmouth.edu/archive/m19w03/public_html/Section6-5.pdf - czy wynik zgadza się z tw. 6.14?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(k, m, nb_simulations):\n",
    "    ...\n",
    "    return avg_nb_integers\n",
    "\n",
    "k = ...\n",
    "m = ...\n",
    "print f(k, m, nb_simulations=...), \"=?=\", m - (k * (1 - 1/float(k))**m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozkład Gaussa - przypomnienie\n",
    "\n",
    "Spróbujmy zaprzyjaźnić się z n-wymiarowym rozkładem Gaussa.\n",
    "\n",
    "wzór na gęstość rozkładu gaussa:\n",
    "\n",
    "$$f(x \\; | \\; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\sigma^2\\pi} } \\; e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }$$\n",
    "\n",
    "wersja n-wymiarowa:\n",
    "https://en.wikipedia.org/wiki/Multivariate_normal_distribution\n",
    "\n",
    "Macierz kowariancji rozkładu n-wymiarowego musi być dodatnio określona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 8 (2 pkt)\n",
    "\n",
    "Napisać funkcję, która przyjmuje parametry rozkładu normalnego: średnią oraz macierz kowariancji, liczbę sampli, a następnie sampluje punkty z tego rozkładu i rysuje na plaszczyźnie. Ponadto na rysunku należy zaznaczyć strzałkami wektory własne macierzy kowariancji (punkt zaczepienia to średnia rozkładu normalnego) i wypisać odpowiadające im wartości własne.\n",
    "\n",
    "Narysować powyższe dla kilku różnych losowo wybranych średnich i macierzy kowariancji (http://stackoverflow.com/questions/619335/a-simple-algorithm-for-generating-positive-semidefinite-matrices).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = ...\n",
    "cov = ...\n",
    "samples = numpy.random.multivariate_normal(mean, cov, size=...)\n",
    "# eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "w, v = np.linalg.eig(cov)\n",
    "...\n",
    "plot\n",
    "\n",
    "# wynik: spodziewamy się elipsy o środku w średniej rozkładu,\n",
    "# tam też powinna być największa gęstość samplowanych punktów;\n",
    "# wektory własne powinny wskazywać kierunki osi elipsy;\n",
    "# jaki jest związek wartości własnych z długościami osi elipsy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 9 (4 pkt)\n",
    "\n",
    "Załóżmy, że mamy dane pochodzące dwuwymiarowego rozkładu normalnego o macierzy kowariancji będącej identycznością i średniej $\\mu$. Będziemy estymowali $\\mu$ korzystając z wzoru Bayesa.\n",
    "\n",
    "1. Stworzyć siatkę 100x100 na kwadracie $[0,1]^2$ - to będą nasze potencjalne średnie.\n",
    "2. Wylosować jeden punkt z siatki - to będzie \"prawdziwa\" średnia rozkładu. Oczywiście model jej nie zna.\n",
    "3. Przyjąć jednostajny rozkład a priori (użyć floatów z największą możliwą precyzją), trzymać go w tablicy knowledge.\n",
    "4. Powtórzyć nb_iters razy:\n",
    "    - wygenerować nb_samples sampli z prawdziwego rozkładu,\n",
    "    - uaktualnić knowledge na podstawie obserwacji,\n",
    "    - narysować knowledge jako dwuwymiarowy heatmap.\n",
    "\n",
    "Sprawdzić, co się stanie, gdy:\n",
    "1. Siatka punktów będzie rzadsza, a prawdziwa średnia rozkładu będzie poza siatką.\n",
    "2. Średnia rozkładu znajdzie się całkowicie poza badanym kwadratem, np. w punkcie $(1.2, 0.7)$.\n",
    "3. Na początku wylosujemy 2 punkty z siatki - $\\mu_1$ i $\\mu_2$ - a następnie obserwacje będziemy samplować naprzemian z dwóch rozkładów gaussa, przy czym cały czas estymujemy $\\mu$ tak, jak gdyby istniało dokładnie jedno prawdziwe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 10 (4 pkt)\n",
    "(proszę najpierw przeczytać uwagę dodaną na czerwono w sekcji \"Podejście maximum likelihood\")\n",
    "\n",
    "Zdarzenie oznaczone $B_1$: Rzucamy dziesięć razy monetą i otrzymujemy wyniki ORZEŁ, ORZEŁ, RESZKA, RESZKA, ORZEŁ, RESZKA, ORZEŁ, ORZEŁ, ORZEŁ, ORZEŁ.\n",
    "\n",
    "Zdarzenie oznaczone $B_2$: Poprosiliśmy kolegę, żeby w naszym imieniu rzucił 10 razy monetą i zanotował wyniki. Kolega - w dobrej wierze - zliczał tylko liczbę orłów, wypadło ich 7.\n",
    "\n",
    "Udowodnić (matematycznie), że dla dowolnego rozkładu a priori parametru $\\theta$ zachodzi równość rozkładów a posteriori:\n",
    "$$P(\\theta\\mid B_1) = P(\\theta\\mid B_2)$$\n",
    "Innymi słowy, kolejność wyników rzutu monetą faktycznie nie niesie za sobą żadnej informacji, która jest przydatna przy estymowaniu parametru $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
